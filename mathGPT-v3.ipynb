{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd1a157",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# install dependencies\n",
    "!{sys.executable} -m pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a42abe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import openai\n",
    "import gradio as gr\n",
    "from langchain import OpenAI, SQLDatabase, SQLDatabaseChain\n",
    "import datetime\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import uuid\n",
    "import subprocess\n",
    "import re\n",
    "import yake\n",
    "import requests\n",
    "import xmltodict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7ffc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for UI\n",
    "\n",
    "def set_openai_api_key(api_key, openai_api_key, pal_chain):\n",
    "    if api_key:\n",
    "        openai_api_key = api_key\n",
    "        os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "        \n",
    "        # Connect to database\n",
    "        db = SQLDatabase.from_uri(\"sqlite:///./testAg.db\")\n",
    "        llm = OpenAI(temperature=0)\n",
    "        db_chain = SQLDatabaseChain(llm=llm, database=db, verbose=True)\n",
    "\n",
    "        os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "\n",
    "        return openai_api_key, db_chain\n",
    "    \n",
    "\n",
    "def openai_create(prompt, openai_api_key):\n",
    "    print(\"prompt: \" + prompt)\n",
    "\n",
    "    # We use temperature of 0.0 because it gives the most predictable, factual answer (i.e. avoids hallucination).\n",
    "    os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
    "    response = openai.Completion.create(\n",
    "        model=\"text-davinci-003\",\n",
    "        prompt=prompt,\n",
    "        temperature=0.0,\n",
    "        max_tokens=300,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0\n",
    "    )\n",
    "    os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "\n",
    "    return response.choices[0].text\n",
    "\n",
    "def calc_gpt_only(prompt, openai_api_key):\n",
    "    if not openai_api_key or openai_api_key == \"\":\n",
    "        return \"<pre>Please paste your OpenAI API key</pre>\"\n",
    "\n",
    "    f = open(\"history.txt\", \"a\")\n",
    "    f.write(prompt + \";\\n\")\n",
    "    \n",
    "    answer = openai_create(prompt + \"\\n\", openai_api_key)\n",
    "    f.write(answer + \"\\n\")\n",
    "\n",
    "    html = \"<pre>\" + answer + \"</pre>\"\n",
    "    return html\n",
    "\n",
    "def calc_gpt_sql(prompt, db_chain):\n",
    "    if not db_chain:\n",
    "        return \"<pre>Please paste your OpenAI API key</pre>\"\n",
    "\n",
    "    f = open(\"history.txt\", \"a\")\n",
    "    f.write(prompt + \";\\n\")\n",
    "    \n",
    "    res = db_chain.run(prompt)\n",
    "    f.write(res + \"\\n\")\n",
    "    html = \"<pre>\" + res + \"</pre>\"\n",
    "    return html\n",
    "\n",
    "\n",
    "MAX_LINES_STOP = 10\n",
    "\n",
    "def get_history(max_lines=MAX_LINES_STOP):\n",
    "    res = \"\"\n",
    "    f = open(\"history.txt\", \"r\")\n",
    "    lines = f.readlines()\n",
    "    for index in range(len(lines)):\n",
    "        if lines[index][-2:] == \";\\n\":\n",
    "            res += \"<li> Question: \" + lines[index][:-2] + \"</li>\"\n",
    "            currentIndex = index+3\n",
    "            counter = 0\n",
    "            answer = \"\"\n",
    "            while counter < max_lines:\n",
    "                if lines[currentIndex][-2:] == \".\\n\":\n",
    "                    break\n",
    "                answer += lines[currentIndex]\n",
    "                currentIndex += 1\n",
    "                counter += 1\n",
    "            res += \"<li> Answer: \" + answer + \"</li>\"\n",
    "    return \"<ul>\" + res + \"</ul>\"\n",
    "\n",
    "def clear_history():\n",
    "    f = open(\"history.txt\", \"w\")\n",
    "    f.close()\n",
    "    return \"<h3> History Cleared! </h3>\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3e4c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wolfram Alpha Short request API\n",
    "def categorization (query, openai_api_key):\n",
    "    categories = [\"Recipe questions\",\"Dishes nutrition questions\",\"Ingredient nutrient questions\",\"Food comparison questions\",\"Food substition questions\",\"Personal diet questions\"]\n",
    "    category = openai_create('\"' + query + '\" Which one of the following categories does this question belong to: ' + ','.join(categories), openai_api_key)\n",
    "    return (category)\n",
    "\n",
    "\n",
    "# Wolfram Alpha Full request API\n",
    "\n",
    "WOLF_ALPHA_APPID = ''\n",
    "BASE_URL = 'http://api.wolframalpha.com/v2/query?appid=' + WOLF_ALPHA_APPID\n",
    "\n",
    "def wolfAlphaFullQuery(query):\n",
    "    split_query = query.split(' ')\n",
    "    formatted_query = ''\n",
    "    for i in range(len(split_query)):\n",
    "        if i == len(split_query)-1:\n",
    "            formatted_query += split_query[i] + '%20'\n",
    "            continue\n",
    "        formatted_query += split_query[i] + '+'\n",
    "    url = BASE_URL + '&input=' + formatted_query\n",
    "    response = requests.get(url)\n",
    "    print('Status Code: ' + str(response.status_code) + '\\n')\n",
    "    if int(response.status_code) != 200:\n",
    "        return \"Could not retrieve answer!\"\n",
    "    result = response.content.decode()\n",
    "    parsedRes = xmltodict.parse(result)\n",
    "    if parsedRes['queryresult']['@success'] == 'false':\n",
    "        return \"Could not retrieve answer! (Query Failed)\"\n",
    "    resArr = []\n",
    "    for obj in parsedRes['queryresult']['pod']:\n",
    "        if int(obj['@numsubpods']) == 1:\n",
    "            resArr.append(obj['subpod']['plaintext'])\n",
    "        else:\n",
    "            for i in obj['subpod']:\n",
    "                resArr.append(i['plaintext'])\n",
    "    strResult = \"\"\n",
    "    for i in resArr:\n",
    "        if type(i) == str:\n",
    "            strResult += i\n",
    "    return strResult\n",
    "\n",
    "\n",
    "def getWolfAlphaAnswers(questions):\n",
    "    question_arr = questions.split(\"\\n\")\n",
    "    result = ''\n",
    "    for i in question_arr:\n",
    "        if len(i) < 3:\n",
    "            continue\n",
    "        result += i + ' ' + wolfAlphaFullQuery(i) + '\\n'\n",
    "    return result\n",
    "\n",
    "def wolfAlphaGpt3Complete(query, open_ai_key):\n",
    "    f = open('history.txt',\"a\")\n",
    "    \n",
    "    p1a = open('promptfa.txt','r')\n",
    "    p1a = p1a.read()\n",
    "    p1b_norm = open ('prompt1b_copy.txt','r')\n",
    "    p1b_norm = p1b_norm.read()    \n",
    "    firstprompt = str (p1a) + query + str(p1b_norm)\n",
    "    questions = openai_create (firstprompt, open_ai_key)\n",
    "    \n",
    "    out1 = getWolfAlphaAnswers(questions)\n",
    "    secondprompt = 'Based on the data, ' + query + 'Data: ' + out1 + '. Please include the data and show the calculations to support your answer'\n",
    "    out2 = openai_create (secondprompt, open_ai_key)\n",
    "    f.write (secondprompt + \";\\n\")\n",
    "    f.write (out2 + \"\\n\")\n",
    "    #print (\"prompt: \" + firstprompt)\n",
    "    print (out1)\n",
    "    print (out2)\n",
    "    return out2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d19a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pseduocode for filecheck\n",
    "\n",
    "# Keyword Extracter\n",
    "    # input is a sentence (based on the prompt)\n",
    "    # Identifies the key words in the prompt\n",
    "    # Returns a list of keywords (top 5)\n",
    "    \n",
    "# file_column\n",
    "    # Input list of files\n",
    "    # Pulls out the columns \n",
    "    # output dictionary with file as the key and columns as the value\n",
    "    \n",
    "# file matching\n",
    "    # Input list of keywords and file columns\n",
    "    # Based on the above output, matches the keywords to the relevant files <- if the keywordsa are is in the file's column it is added\n",
    "    # Returns dictionary of relevant file (key) and the columns (value)\n",
    "\n",
    "# Rel_files\n",
    "    # Input prompt and list of files\n",
    "    # Runs keyword extracter\n",
    "    # Runs file_column\n",
    "    # runs file matching with the keyword extracter and file column\n",
    "    # Outputs a prompt that specifies which files to use based on the number of relevant files\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a18213a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the relevant files\n",
    "\n",
    "# Add more files here \n",
    "\n",
    "\n",
    "def keyword_extracter (prompt):\n",
    "    keyword_list = []\n",
    "    kw_extractor = yake.KeywordExtractor(top=5, stopwords=None)\n",
    "    keywords = kw_extractor.extract_keywords(prompt)\n",
    "    for kw, v in keywords:\n",
    "        keyword_list.append(str(kw))\n",
    "    return keyword_list \n",
    "\n",
    "# Identifying columns from a list of files\n",
    "def file_columns (file_list):\n",
    "    file_col = {}\n",
    "    for file in file_list:\n",
    "        if \".csv\" in file:\n",
    "            df = pd.read_csv(file)\n",
    "            column_names = list(df.columns.values)\n",
    "            file_col[file] = column_names\n",
    "            continue\n",
    "        elif \".xlsx\" in file:\n",
    "            df = pd.read_excel(file)\n",
    "            column_names = list(df.columns.values)\n",
    "            file_col[file] = column_names\n",
    "        return file_col\n",
    "\n",
    "# Matching keywords to the column names of files\n",
    "def file_matching (keyword_list, file_col):\n",
    "    relevant_files = {}\n",
    "    for keyw in keyword_list:    \n",
    "        for file, columns in file_col.items(): \n",
    "            for col in columns:\n",
    "                if keyw.lower() in col.lower():\n",
    "                    if file not in relevant_files:\n",
    "                        relevant_files [file] = file_col[file]\n",
    "    return relevant_files\n",
    "\n",
    "# Running all of the above <- returns list of relevant files\n",
    "def rel_files (prompt, file_list):\n",
    "    keyword_list = keyword_extracter(prompt)\n",
    "    file_col = file_columns (file_list)\n",
    "    file_relevant = file_matching (keyword_list, file_col)\n",
    "    # Print if file_relevant is just one file\n",
    "    if len(file_relevant) == 0:\n",
    "        return \". \"\n",
    "    if len (file_relevant) ==1: \n",
    "        return (\". Use \" + '\"' + str(list(file_relevant.items())[0][0]) + '\" ' + \" to answer this. It contains the columns: \" + str(list(file_relevant.items())[0][1]) + '. ') \n",
    "    # Adding on to the string when there are more than one relevant files\n",
    "    if len (file_relevant) > 1: \n",
    "        string_output = \". Use some of the following files to answer this: \"\n",
    "        final_string = string_output\n",
    "        for file, cols in file_relevant.items():\n",
    "            additional_string = '\"' + str (file) + '\" ' + \"which contains the following columns: \" + ', '.join(cols) + ', '\n",
    "            final_string += additional_string\n",
    "        return (final_string[:-2] + '. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bfa276",
   "metadata": {},
   "outputs": [],
   "source": [
    "## R code\n",
    "\n",
    "gpt_only_prompt = \"\"\n",
    "\n",
    "def openai_create (prompt, openai_api_key):\n",
    "    response = openai.Completion.create (\n",
    "    model=\"text-davinci-003\",\n",
    "    prompt=prompt,\n",
    "    temperature=0.0,\n",
    "    max_tokens=300,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0\n",
    "    )\n",
    "    os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "    return response.choices[0].text\n",
    "\n",
    "def gpt_code (coderequest, openai_api_key):\n",
    "#     filerequest = \"Use AgSensorDataF037-renamed.csv to answer this. The file has columns of data named Time,Temperature,Humidity,Pressure,Soil_Moisture,Wind_Speed,Wind_Direction,Ambient_Temperature,Ambient_Humidity,Battery. Generate a code in R language to analyze it. Output only R code, ignore pretext and start with loading of libraries. Do not plot anything. The code should print out the answer. Install all the packages needed, choose the repository from http://cran.us.r-project.org.\"\n",
    "#     filerequest = \"Generate a code in R language to analyze it. Output only R code, ignore pretext and start with loading of libraries. Do not plot anything. The code should print out the answer. Install all the packages needed, choose the repository from http://cran.us.r-project.org.\"\n",
    "    \n",
    "    # Extracting the keywords from the prompt\n",
    "    file_list = [\"AgSensorDataF037-renamed.csv\",\"demoData.xlsx\"]\n",
    "    filerequest = rel_files(coderequest,file_list)\n",
    "    postrequest = \"Generate a code in R language to analyze it. Output only R code, ignore pretext and start with loading of libraries. Do not plot anything. The code should print out the answer. Install packages if needed, choose the repository from http://cran.us.r-project.org. Do not install packages if already installed.\"\n",
    "    print (coderequest + filerequest + postrequest)\n",
    "\n",
    "    # Talk more about the data ie what columns they have\n",
    "    answer = openai_create (coderequest + filerequest + postrequest, openai_api_key)\n",
    "    # data = pd.read_excel(file)\n",
    "    print(\"coding question: \" + coderequest)\n",
    "    print(\"code: \" + answer)\n",
    "    return answer\n",
    "\n",
    "def rewrite_code_prompt(filename):\n",
    "    code = \"\"\n",
    "    f = open(filename, \"r\")\n",
    "    for i in f:\n",
    "        code.append(i)\n",
    "    prompt = \"Rewrite the following R code to print the result\" + code # Add print only r code\n",
    "    return prompt\n",
    "\n",
    "def install_package_prompt(filename, package):\n",
    "    code = \"\"\n",
    "    f = open(filename, \"r\")\n",
    "    for i in f:\n",
    "        code.append(i)\n",
    "    prompt = \"Install the R package \" + package + \" and run\" + code # Add print only r code\n",
    "    return prompt\n",
    "\n",
    "def chatgpt_code (prompt2, openai_api_key):\n",
    "    # Create the R script\n",
    "    filename = str(uuid.uuid4())\n",
    "    # ans = gpt_code(prompt2, openai_api_key)\n",
    "    with open(filename + '.R', 'w') as fi:\n",
    "        fi.write(gpt_code(prompt2, openai_api_key) + '\\n')\n",
    "\n",
    "    # Run the R script and capture the output\n",
    "    result = subprocess.run(['Rscript', filename + '.R'], capture_output=True)\n",
    "    temp = str(result.stdout.decode())\n",
    "    err = str(result.stderr.decode())\n",
    "    \n",
    "    # Parse result (David 2 Feb)\n",
    "    print(temp)\n",
    "    regex = re.search(\"\\[.\\](.|\\n)*\", temp)\n",
    "    if not regex:\n",
    "        temp = ''\n",
    "\n",
    "#     if len(temp) > 0:\n",
    "#         Check validity (Future)\n",
    "    \n",
    "    NO_OF_RETRIES = 3\n",
    "    counter = 0\n",
    "    while len(temp) == 0 and counter < NO_OF_RETRIES:\n",
    "        regex = re.search(\"\\[.\\](.|\\n)*\", temp)\n",
    "        if not regex:\n",
    "            temp = ''\n",
    "        if len(err) > 0:\n",
    "            if \"No such file or directory\" in err:\n",
    "                split_string = err.split(\" \")\n",
    "                missing_file = \"\"\n",
    "                for i in split_string:\n",
    "                    if i[0] == \"'\" and i[-1] == \"'\":\n",
    "                        missing_file = i[1:-1]\n",
    "                # Might have to try 3 times and correct file\n",
    "                return missing_file + \"cannot be found\"\n",
    "            \n",
    "            if \"there is no package called \" in err:\n",
    "                split_string = err.split(\" \")\n",
    "                missing_package = \"\"\n",
    "                for i in split_string:\n",
    "                    if i[0] == \"'\" and i[-1] == \"'\":\n",
    "                        missing_package = i[1:-1]\n",
    "                new_code_prompt = install_package_prompt(filename, missing_package)\n",
    "                new_ans = openai_create(new_code_prompt, openai_api_key)\n",
    "                new_filename = str(uuid.uuid4())\n",
    "                with open(new_filename+'.R', 'w') as file:\n",
    "                    file.write(answer + '\\n')\n",
    "                result = subprocess.run(['Rscript', new_filename + '.R'], capture_output=True)\n",
    "                temp = str(result.stdout.decode())\n",
    "                err = str(result.stderr.decode())\n",
    "\n",
    "        if len(err) == 0:\n",
    "            new_code_prompt = rewrite_code_prompt(filename)\n",
    "            new_ans = openai_create(new_code_prompt, openai_api_key)\n",
    "            new_filename = str(uuid.uuid4())\n",
    "            with open(new_filename+'.R', 'w') as file:\n",
    "                file.write(answer + '\\n')\n",
    "            result = subprocess.run(['Rscript', new_filename + '.R'], capture_output=True)\n",
    "            temp = str(result.stdout.decode())\n",
    "            err = str(result.stderr.decode())\n",
    "\n",
    "        counter += 1\n",
    "    \n",
    "    if len(temp) == 0:\n",
    "        return \"<h2> Please Try Again! </h2>\"    \n",
    "\n",
    "    result = regex.group(0)\n",
    "    \n",
    "    r2 = (\"\\nOutput:\\n\" + result)\n",
    "    f = open(\"history.txt\", \"a\")\n",
    "    \n",
    "    f.write(prompt2 + \";\\n\")\n",
    "    f.write(r2 + \".\\n\")\n",
    "    return (r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14c18ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UI HTML\n",
    "\n",
    "block = gr.Blocks(css=\".gradio-container {background-color: lightgray}\")\n",
    "\n",
    "with block:\n",
    "    with gr.Row():\n",
    "        title = gr.Markdown(\"\"\"<h3><center>Ask me anything!</center></h3>\"\"\")\n",
    "\n",
    "        openai_api_key_textbox = gr.Textbox(placeholder=\"Paste your OpenAI API key (sk-...)\",\n",
    "                                            show_label=False, lines=1, type='password')\n",
    "\n",
    "    answer_html = gr.Markdown()\n",
    "\n",
    "    request = gr.Textbox(label=\"Question:\",\n",
    "                         placeholder=\"Ex: Are the conditions suitable for planting corn?\")\n",
    "    with gr.Row():\n",
    "        gpt_only = gr.Button(value=\"GPT Only\", variant=\"secondary\").style(full_width=False)\n",
    "        gpt_pal = gr.Button(value=\"GPT w/SQL\", variant=\"secondary\").style(full_width=False)\n",
    "        gpt_r = gr.Button(value=\"GPT w/R\", variant=\"secondary\").style(full_width=False)\n",
    "        wolf_alpha = gr.Button(value=\"Wolfram Alpha\", variant=\"secondary\").style(full_width=False)\n",
    "        history = gr.Button(value=\"History\", variant=\"secondary\").style(full_width=False)\n",
    "        clear_hist = gr.Button(value=\"Clear History\", variant=\"secondary\").style(full_width=False)\n",
    "\n",
    "    openai_api_key_state = gr.State()\n",
    "    pal_chain_state = gr.State()\n",
    "\n",
    "    gpt_only.click(calc_gpt_only, inputs=[request, openai_api_key_state], outputs=[answer_html])\n",
    "    gpt_pal.click(calc_gpt_sql, inputs=[request, pal_chain_state], outputs=[answer_html])\n",
    "    gpt_r.click (chatgpt_code, inputs=[request, openai_api_key_state], outputs=[answer_html])\n",
    "    wolf_alpha.click(wolfAlphaGpt3Complete, inputs=[request, openai_api_key_state], outputs=[answer_html])\n",
    "    history.click(get_history, inputs=[], outputs=[answer_html])\n",
    "    clear_hist.click(clear_history, inputs=[], outputs=[answer_html])\n",
    "    \n",
    "    openai_api_key_textbox.change(set_openai_api_key,\n",
    "                                  inputs=[openai_api_key_textbox, openai_api_key_state, pal_chain_state],\n",
    "                                  outputs=[openai_api_key_state, pal_chain_state])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65647e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "block.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1a9734",
   "metadata": {},
   "source": [
    "\n",
    "Addition to prompt: Be specific about the type of food in the queries, break recipes down into their individual components and use the following format to generate questions: What is the amount of nutrition x in food y \n",
    "1. More general questions such as: \"What type of food should I eat if I am diabetic / want to lose weight / have vitamin deficiencies etc \n",
    "2. User specific questions: \"I am x years old, male/female, weighing x, what type of foods should I eat\" /n\n",
    "3. Recipe questions: 'How do i make french toast' <- includes nutrional information /n\n",
    "4. Comparison questions: 'Which is healthier beef or chicken' /n\n",
    "5. Food substitution questions: 'What is a good substitute for butter \n",
    "Also, answers will now include data from Wolfman Alpha to support the answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1b65b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b91fe2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91daa39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
