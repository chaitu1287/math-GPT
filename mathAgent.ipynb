{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7c9256",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import langchain\n",
    "from langchain import OpenAI, SerpAPIWrapper\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.agents import load_tools\n",
    "import requests\n",
    "import openai\n",
    "\n",
    "# API Keys\n",
    "os.environ[\"SERPAPI_API_KEY\"] = \"\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "\n",
    "# Models\n",
    "chatgpt = ChatOpenAI(model_name='gpt-3.5-turbo')\n",
    "gpt3 = OpenAI(model_name='text-davinci-003')\n",
    "\n",
    "# Template Queries\n",
    "FIRST_TASK = \" Your first task is to figure out what your first task is, then come up with a plan on how to carry it out\"\n",
    "ALL_TASKS = \" Your first task is to figure out what your tasks are, then plan how to do them\"\n",
    "FIRST_TASK = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acce9d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wolfram Alpha API\n",
    "WOLF_ALPHA_APPID = ''\n",
    "BASE_URL = 'http://api.wolframalpha.com/v1/spoken?appid=' + WOLF_ALPHA_APPID\n",
    "\n",
    "def wolfAlphaQuery(query):\n",
    "    split_query = query.split(' ')\n",
    "    formatted_query = ''\n",
    "    for i in range(len(split_query)):\n",
    "        if i == len(split_query)-1:\n",
    "            formatted_query += split_query[i] + '%3f'\n",
    "            continue\n",
    "        formatted_query += split_query[i] + '+'\n",
    "    url = BASE_URL + '&i=' + formatted_query\n",
    "    response = requests.get(url)\n",
    "    if int(response.status_code) != 200:\n",
    "        return f\"Could not retrieve answer! (Status Code {response.status_code})\"\n",
    "    result = response.content.decode()\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b900bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to list all tasks\n",
    "def createTaskList(prompt):\n",
    "    prompt = f\"You are an task creation AI that uses the result of an execution agent to create new tasks with the following objective: {prompt}. Return the tasks as an array.\"\n",
    "    response = openai.Completion.create(engine=\"text-davinci-003\",prompt=prompt,temperature=0.5,max_tokens=100,top_p=1,frequency_penalty=0,presence_penalty=0)\n",
    "    result = response.choices[0].text.strip().split('\\n')\n",
    "    textResult = \"\"\n",
    "    for i in result:\n",
    "        textResult += i + '\\n'\n",
    "    return textResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6080b333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to prioritize tasks\n",
    "def prioritizeTaskList(tasks):\n",
    "    prompt = f\"\"\"You are an task prioritization AI tasked with reprioritizing the following tasks: {tasks}. Do not add, remove or modify any tasks. Return the result as a numbered list, like:\n",
    "    #. First task\n",
    "    #. Second task\"\"\"\n",
    "    response = openai.Completion.create(engine=\"text-davinci-003\",prompt=prompt,temperature=0.5,max_tokens=100,top_p=1,frequency_penalty=0,presence_penalty=0)\n",
    "    result = response.choices[0].text.strip().split('\\n')\n",
    "    textResult = \"\"\n",
    "    for i in result:\n",
    "        textResult += i + '\\n'\n",
    "    return textResult\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22a1a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute each task separately\n",
    "def executeTask(tasks):\n",
    "    prompt = f\"Tell me how to carry out these task: {tasks}, write the steps separately for each task\"\n",
    "    response = openai.Completion.create(engine=\"text-davinci-003\",prompt=prompt,temperature=0.5,max_tokens=100,top_p=1,frequency_penalty=0,presence_penalty=0)\n",
    "    result = response.choices[0].text.strip().split('\\n')\n",
    "    textResult = \"\"\n",
    "    for i in result:\n",
    "        textResult += i + '\\n'\n",
    "    return textResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56eac7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use GPT3 to create a suitable query for Wolfram Alpha\n",
    "def getWolfAlphaAnswers(questions):\n",
    "    question_arr = questions.split(\"\\n\")\n",
    "    result = ''\n",
    "    for i in question_arr:\n",
    "        if len(i) < 3:\n",
    "            continue\n",
    "        result += i + ' ' + wolfAlphaQuery(i) + '\\n'\n",
    "    return result\n",
    "\n",
    "def wolframAlphaKnowledgeQuery(query):\n",
    "    p1a = open('promptfa.txt','r')\n",
    "    p1a = p1a.read()\n",
    "    p1b_norm = open ('prompt1b_copy.txt','r')\n",
    "    p1b_norm = p1b_norm.read()    \n",
    "    firstprompt = str (p1a) + query + str(p1b_norm)\n",
    "    response = openai.Completion.create(engine=\"text-davinci-003\",prompt=firstprompt,temperature=0.5,max_tokens=100,top_p=1,frequency_penalty=0,presence_penalty=0)\n",
    "    questions = response.choices[0].text.strip()\n",
    "    out1 = getWolfAlphaAnswers(questions)\n",
    "    return out1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9628e11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Think about how to improve the correctness of our result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b98725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer checking\n",
    "def gpt3_isCorrect(question, answer):\n",
    "    Q = \"Question: \" + question + \"\\n\"\n",
    "    A = \"Answer: \" + answer + \"\\n\\n\"\n",
    "    PROMPT = \"Is the above answer appropriate for the above question, yes or no?\"\n",
    "    REGENERATE_PROMPT = \" If not, suggest a change in the prompt to generate the appropriate answer.\"\n",
    "    COMBINED = Q + A + PROMPT\n",
    "    \n",
    "    response = openai.Completion.create(\n",
    "        model=\"text-davinci-003\",\n",
    "        prompt=COMBINED,\n",
    "        temperature=0.0,\n",
    "        max_tokens=300,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0\n",
    "    )\n",
    "    \n",
    "    txt_res = response.choices[0].text.strip()\n",
    "    sliced = txt_res[0:3].lower()\n",
    "    return sliced == 'yes'\n",
    "\n",
    "# Test\n",
    "# gpt3_isCorrect(\"1+2\", \"3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a4cddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY=\"Create a completed 3 day healthy meal plan for me\"\n",
    "\n",
    "FINAL = QUERY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5aea043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add wolfram alpha tool to do math and check how it runs\n",
    "# Calculate first 100 prime numbers\n",
    "# Find out how the logic is flowing\n",
    "\n",
    "# Logic Flow:\n",
    "# Seems to decide which tool to use based on name and description\n",
    "search = SerpAPIWrapper()\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Web Search (SERP API)\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to ask with search\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Wolfram Alpha\",\n",
    "        func=wolfAlphaQuery,\n",
    "        description=\"useful for math calculations\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Task Creation\",\n",
    "        func=createTaskList,\n",
    "        description=\"useful for when you need to generate a list of tasks\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Task Prioritization\",\n",
    "        func=prioritizeTaskList,\n",
    "        description=\"useful for when you have a list of tasks that need to be prioritized\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Task Execution\",\n",
    "        func=executeTask,\n",
    "        description=\"useful for when you have a task that needs to be carried out\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Wolfram Alpha Knowledge Query\",\n",
    "        func=wolframAlphaKnowledgeQuery,\n",
    "        description=\"useful for when you want to obtain nutritional information\"\n",
    "    ),\n",
    "]\n",
    "agent = initialize_agent(tools, llm=gpt3, agent=\"zero-shot-react-description\", verbose=True)\n",
    "# Find out different agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85b2120",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = agent.run(FINAL)\n",
    "ITERS = 3\n",
    "counter = 0\n",
    "\n",
    "while counter < ITERS-1 and not gpt3_isCorrect(FINAL, result):\n",
    "    print(\"Rerunning agent.run\")\n",
    "    result = agent.run(FINAL)\n",
    "    counter += 1\n",
    "\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
